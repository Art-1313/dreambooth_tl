# Dreambooth

## В чём проблема?

Большие модели для генерации изображений по текстовому описанию достигли значительных успехов в последнее время. Однако, не смотря на высокое качество и разноообразность получающихся картинок, эти модели не могут генерировать конткретный объект в различных условия, сохраняя все его основные свойства. 

Эту задачу можно сфоромулировать следующим образом: **по имеющемуся набору изображений объекта обучить сеть генерировать изображения этого объекта в различных условиях с сохранением его отиличительных визуальных признаков**.

Решение этой задачи имеет практическое применение, например, создатели коммиксов или мультфильмов смогут рисовать персонажей и использовать нейросети для помещения их в какой-нибудь контекст.

## Решение

Одно из возможных решений представленно в статье `DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation` (https://arxiv.org/abs/2208.12242). Авторы предлагают создавать уникальный индетификатор объекта, который не будет активно встречаться в словаре предобученной модели, и дообучит модель генерировать картинки, схожие с исходными.

Для того, чтобы избежать так называеммого `language drift` (когда доубученная модель теряет свои изначальные знания и перестаёт генерировать адекватные изображения на запросы), авторы исполльзуют технику `Class-specific Prior Preservation Loss`, которая заключается в том, что в запрос при обучении вместе с уникальным идентификатором добавляется метка класса объекта (например, соба или человек). Изначальная модель генерирует несколько изображений класса, после чего они используются для сравнения картинок этого класса сгенерированных дообученной моделью. Это позволяет сохранять изначальные знания сети, а так же делает последующую генерацию цлевого объекта более гибкой. Математически функции потерь выглядит следующим образом:

<img width="443" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/e5cf2b73-02b2-4176-b532-ec1e2c03cf94">

Здесь первое слагаемое описывает схожесть между изображениями целевого объекта, второе - между изображениями класса. Вот как это выглядит на схеме:

<img width="521" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/b15d83f1-7e47-497f-919e-175e8493bab9">

Авторы утверждают, что их работа является первой, которая смогла успешно решить проблему генерации объекта в новых контекстах. В статье упоминаются другие методы, пытающиеся решить данную задачу, однако они имеют большое количество недостатков (требуется много тренеровочных изображений, необходимость использования масок для сохранение области от изменений при новой генерации, ограниченность домена, плохая работа с освещением и другие). Поэтому данная работа и правда является новаторской, предлагая простой довольно простой в использовании инструмент, дающий хороший реультат.

Для оценки результатов авторы разработали три метрики качества: `DINO`, `CLIP-I`, `CLIP-T`. Первые две метрики используются для оценки схожетси между эмбедингами сгенерированных и реальных изображений (считаются косинусные расстояние для эмбедингов ViT-S/16 DINO и CLIP соответственно). Авторы считают метрику DINO более показательной, так как в силу своего устройства она не игнорирует отличительные признаки между объектами одного класса, что как раз важно для рассматриваемой задачи (также было обнаружено, что DINO сильнее коррелирует с опросом людей). Метрика CLIP-T оценивает насколько сгенерированное изоюражение соответствует текстовой инструкции. Также авторы провели опрос, в котором предлагалось сравнить сгенерированные изображения с реальными. Результаты сравнения с методом `Textual Inversion`, который решает задачу другим способом, показаны в таблицах ниже:

<img width="517" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/f2eaf5f6-e6cb-4984-b351-722946fdfd64">
<img width="508" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/176f8e96-1b24-4e04-8d4c-4976d09077f1">

В статье авторы проверили также, влияют ли на результат новые методы (функция потерь и дополнительное указание родительского класса объекта). В таблицах ниже предстваленны значения метрик с использованием и без использования новых методов:

<img width="505" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/a67c1c8f-2a30-4fbd-8ce8-d86f628d0e89">
<img width="257" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/c445f8e8-9d95-4b3b-bb55-6c6889135bf2">

В первой таблице сравнивается качество без новой функции потерь и с нею. Помимо ранее описанных метрик здесь также использовались метрки `PRES` (соответсвие родительскому классу) и `DIV` (разнообразие получившихся изображений). Из таблицы видно, что использование новой функции потерь (первая строчка) повышает соотвествие родительскому классу и разнообразие итоговых картинок, также наблюдается большее соответствие текстовой инструкции. Однако хуже схожесть с реальными изображениями. Это объясняется тем, что генерация с использованием функции потерь ориентируется на изображения родительского класса, которые могут находится в разных позах и условиях, что и приводит к наблюдаемым результатам. Это проиллюстрированно ниже:

<img width="523" alt="image" src="https://github.com/Art-1313/dreambooth_tl/assets/71838986/d98520aa-a67e-439d-937f-f72a79a5a523">

Во второй таблице сравнивается качество с использование родительского класса в инструкции и без него. Видно, что использование родительского класса повышает качество.

## Практика

Попрубем воспроизвести результаты на практике. В качестве тренировочного датасета возьмём шесть изображений лица человека. В качестве предобученной модели используем Stable Diffusion 1.5.

Для того, чтобы ускорить время обучения и уменьшить требуемые вычислительные ресурсы воспользуемся методом `LoRA`. Этот метод заключается в том, что вместо привычного дообучения, когда изменяются все праметры в матрицах весов модели (которых в нашем случае довольно много), обучаются матрицы гораздо меньшего размера и добавляются затем к исходным матрицам:

$$W=W_0+\Delta W=W_0+BA$$

Здесь $W_0 \in R^{n \times m}$ - изначальные веса, $B \in R^{n \times r}$ и $A \in R^{r \times m}$ - матрицы меньшего размера $r \ll n,m$. Такой метод применим в данном случае, так как нам нужно внедрить новый объект какого-то класса, который в общем схож с остальными объектами этого класса, а значит достаточно внести изменения на каком-то подмногообразии в пространстве весов, не трогая всё остальное. Также LoRA позволяет сохранить исходную модель и добавлятб изменения в веса в необходимой пропорции, что может помочь побороть language drift.

Основной проблемой при обучении Dreambooth моделей является их склонность к быстрому переобучению. Поэтому основными гиперпараметрами, влияющими на успех будут количество эпох и learning rate. Также на качесвто может влиять обучение текстового энкодера. Влияние этих параметров было исследованно мною в https://shorturl.at/dgH14 Размерность $r$ матриц $A$ и $B$ была взята равной 4 (значение по умолчанию в тренировочном коде) и не варьировалась, так как согласно статье `LoRA: Low-Rank Adaptation of Large Language Models` (https://arxiv.org/abs/2106.09685) в задачах, где домен не сильно отличается от исходного, достаточно малых значений $r$.

На этапе инференса никакие параметры не менялись. Значение `guideline`, отвечающее за приверженность текстовому описанию равнялось 7.5, вклад весов LoRA равнялся 0.5, количесвто шагов генерации равнялось 50.
